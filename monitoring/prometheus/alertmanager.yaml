# AlertManager Configuration for NetworkX MCP Server
#
# Routes alerts based on severity and team ownership
# Integrates with PagerDuty, Slack, and email

global:
  resolve_timeout: 5m
  
  # SMTP configuration for email alerts
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'mcp-alerts@example.com'
  smtp_auth_username: 'mcp-alerts@example.com'
  smtp_auth_password: '$SMTP_PASSWORD'
  smtp_require_tls: true
  
  # Global settings
  slack_api_url: '$SLACK_WEBHOOK_URL'
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

# Templates for alert formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree for alert routing
route:
  # Default receiver for uncategorized alerts
  receiver: 'platform-team'
  
  # Group alerts by these labels
  group_by: ['alertname', 'cluster', 'service', 'severity']
  
  # Wait before sending grouped alerts
  group_wait: 30s
  
  # Wait before sending new alerts for a group
  group_interval: 5m
  
  # Wait before re-sending alerts
  repeat_interval: 4h
  
  # Child routes for specific routing
  routes:
    # Critical alerts - immediate paging
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      group_wait: 10s
      repeat_interval: 1h
      routes:
        # Security critical alerts go to security team
        - match:
            team: security
          receiver: 'security-pagerduty'
          
    # Warning alerts - Slack notifications
    - match:
        severity: warning
      receiver: 'platform-slack'
      group_wait: 1m
      repeat_interval: 4h
      
    # Info alerts - email only
    - match:
        severity: info
      receiver: 'platform-email'
      group_wait: 5m
      repeat_interval: 12h
      
    # Development environment - reduced alerting
    - match:
        environment: development
      receiver: 'dev-slack'
      group_wait: 5m
      repeat_interval: 24h
      
    # Specific alert routing
    - match:
        alertname: MCPHighMemoryUsage
      receiver: 'platform-team-memory'
      group_wait: 2m
      
    - match:
        alertname: MCPConnectionPoolExhausted
      receiver: 'platform-scaling'
      group_wait: 30s
      
    # Security alerts
    - match_re:
        alertname: '^MCP.*Auth.*|^MCP.*Security.*'
      receiver: 'security-team'
      group_wait: 1m

# Inhibition rules - suppress certain alerts when others are firing
inhibit_rules:
  # Don't alert on high error rate if service is down
  - source_match:
      alertname: 'MCPServerDown'
    target_match:
      alertname: 'MCPHighErrorRateCritical'
    equal: ['instance']
    
  # Don't alert on component health if server is down
  - source_match:
      alertname: 'MCPAllPodsDown'
    target_match_re:
      alertname: 'MCP.*'
    equal: ['cluster']
    
  # Don't alert on slow algorithms if memory is critical
  - source_match:
      alertname: 'MCPMemoryCritical'
    target_match:
      alertname: 'MCPSlowAlgorithms'
    equal: ['instance']
    
  # Suppress warnings when critical alerts are active
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

# Receiver configurations
receivers:
  # Default platform team receiver
  - name: 'platform-team'
    email_configs:
      - to: 'platform-team@example.com'
        headers:
          Subject: '[MCP Alert] {{ .GroupLabels.alertname }} - {{ .GroupLabels.severity }}'
    slack_configs:
      - channel: '#mcp-alerts'
        title: 'MCP Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        
  # PagerDuty for critical alerts
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '$PAGERDUTY_SERVICE_KEY'
        severity: 'critical'
        client: 'NetworkX MCP Server'
        client_url: 'https://grafana.example.com/d/networkx-mcp-prod'
        description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          cluster: '{{ .GroupLabels.cluster }}'
          
  # Platform Slack channel
  - name: 'platform-slack'
    slack_configs:
      - channel: '#platform-alerts'
        username: 'MCP AlertManager'
        icon_emoji: ':warning:'
        title: '{{ .GroupLabels.alertname }} ({{ .GroupLabels.severity }})'
        text: |
          *Summary:* {{ .CommonAnnotations.summary }}
          *Description:* {{ .CommonAnnotations.description }}
          *Severity:* {{ .GroupLabels.severity }}
          *Alerts:* {{ .Alerts.Firing | len }} firing, {{ .Alerts.Resolved | len }} resolved
          <{{ .CommonAnnotations.dashboard }}|View Dashboard>
        send_resolved: true
        
  # Platform email
  - name: 'platform-email'
    email_configs:
      - to: 'platform-oncall@example.com'
        html: |
          <h2>{{ .GroupLabels.alertname }}</h2>
          <p><b>Severity:</b> {{ .GroupLabels.severity }}</p>
          <p><b>Summary:</b> {{ .CommonAnnotations.summary }}</p>
          <p><b>Description:</b> {{ .CommonAnnotations.description }}</p>
          {{ if .CommonAnnotations.runbook }}
          <p><b>Runbook:</b> <a href="{{ .CommonAnnotations.runbook }}">{{ .CommonAnnotations.runbook }}</a></p>
          {{ end }}
          <h3>Alerts</h3>
          <ul>
          {{ range .Alerts }}
          <li>{{ .Labels.instance }} - {{ .Status }}</li>
          {{ end }}
          </ul>
          
  # Security team pager
  - name: 'security-pagerduty'
    pagerduty_configs:
      - service_key: '$SECURITY_PAGERDUTY_KEY'
        severity: 'critical'
        description: 'Security Alert: {{ .GroupLabels.alertname }}'
        
  # Security team notifications
  - name: 'security-team'
    email_configs:
      - to: 'security-team@example.com'
    slack_configs:
      - channel: '#security-alerts'
        username: 'MCP Security'
        icon_emoji: ':lock:'
        color: 'danger'
        
  # Development notifications
  - name: 'dev-slack'
    slack_configs:
      - channel: '#mcp-dev'
        username: 'MCP Dev Alerts'
        send_resolved: false
        
  # Specialized receivers for specific alerts
  - name: 'platform-team-memory'
    slack_configs:
      - channel: '#platform-alerts'
        title: 'Memory Alert'
        text: |
          *Memory Usage:* {{ .CommonAnnotations.summary }}
          *Context:* {{ .CommonAnnotations.context }}
          *Action:* Check for large graphs or memory leaks
          
  - name: 'platform-scaling'
    slack_configs:
      - channel: '#platform-alerts'
        title: 'Scaling Required'
        text: |
          *Connection Pool:* {{ .CommonAnnotations.summary }}
          *Action:* {{ .CommonAnnotations.action }}
          Immediate scaling may be required to maintain service quality.
        color: 'danger'
    pagerduty_configs:
      - service_key: '$PAGERDUTY_SERVICE_KEY'
        severity: 'warning'
        description: 'Scaling Required: {{ .CommonAnnotations.summary }}'