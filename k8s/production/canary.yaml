apiVersion: apps/v1
kind: Deployment
metadata:
  name: networkx-mcp-canary
  namespace: default
  labels:
    app: networkx-mcp
    version: canary
    tier: production
spec:
  replicas: 1  # Single canary instance
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 1
  selector:
    matchLabels:
      app: networkx-mcp
      version: canary
  template:
    metadata:
      labels:
        app: networkx-mcp
        version: canary
        tier: production
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
        deployment.kubernetes.io/revision: "${GITHUB_SHA:0:8}"
    spec:
      containers:
      - name: mcp-server
        image: ${IMAGE}
        imagePullPolicy: Always
        command: ["python", "-m", "networkx_mcp", "--jsonrpc"]
        
        ports:
        - name: health
          containerPort: 8080
        - name: metrics
          containerPort: 9090
          
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: LOG_LEVEL
          value: "INFO"
        - name: LOG_FORMAT
          value: "json"
        - name: STORAGE_BACKEND
          value: "redis"
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-credentials
              key: url
        - name: AUTH_TOKEN
          valueFrom:
            secretKeyRef:
              name: mcp-auth
              key: token
        - name: MAX_CONCURRENT_CONNECTIONS
          value: "45"  # Production limits from testing
        - name: MAX_GRAPH_SIZE_NODES
          value: "10000"
        - name: MAX_MEMORY_MB
          value: "2048"
        - name: ENABLE_AUTH
          value: "true"
        - name: TRACING_ENABLED
          value: "true"
        - name: JAEGER_ENDPOINT
          value: "jaeger-collector:14268"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        # Canary-specific labels
        - name: CANARY_DEPLOYMENT
          value: "true"
        - name: DEPLOYMENT_VERSION
          value: "${GITHUB_SHA:0:8}"
          
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
            
        livenessProbe:
          httpGet:
            path: /health
            port: health
          initialDelaySeconds: 15
          periodSeconds: 20
          timeoutSeconds: 5
          failureThreshold: 3
          
        readinessProbe:
          httpGet:
            path: /ready
            port: health
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 2
          
        startupProbe:
          httpGet:
            path: /startup
            port: health
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 6
          
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
          runAsUser: 1000
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
            
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /app/cache
        - name: logs
          mountPath: /app/logs
          
      securityContext:
        fsGroup: 1000
        
      volumes:
      - name: tmp
        emptyDir:
          sizeLimit: 100Mi
      - name: cache
        emptyDir:
          sizeLimit: 200Mi
      - name: logs
        emptyDir:
          sizeLimit: 100Mi
          
      terminationGracePeriodSeconds: 35
      
      # Ensure canary doesn't interfere with stable
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - networkx-mcp
                - key: version
                  operator: NotIn
                  values:
                  - canary
              topologyKey: kubernetes.io/hostname

---
# Canary Service (separate from main service)
apiVersion: v1
kind: Service
metadata:
  name: networkx-mcp-canary-service
  labels:
    app: networkx-mcp
    version: canary
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
spec:
  selector:
    app: networkx-mcp
    version: canary
  ports:
  - name: health
    port: 8080
    targetPort: health
  - name: metrics
    port: 9090
    targetPort: metrics
  type: ClusterIP

---
# Canary Ingress with traffic splitting
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: networkx-mcp-canary-ingress
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-weight: "${CANARY_WEIGHT}"
    nginx.ingress.kubernetes.io/canary-by-header: "X-Canary"
    nginx.ingress.kubernetes.io/canary-by-header-value: "always"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - api.mcp.example.com
    secretName: mcp-api-tls
  rules:
  - host: api.mcp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: networkx-mcp-canary-service
            port:
              number: 8080

---
# ServiceMonitor for canary metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: networkx-mcp-canary-metrics
  labels:
    app: networkx-mcp
    version: canary
spec:
  selector:
    matchLabels:
      app: networkx-mcp
      version: canary
  endpoints:
  - port: metrics
    interval: 15s  # More frequent monitoring for canary
    path: /metrics
    timeout: 10s
  jobLabel: app